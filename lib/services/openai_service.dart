import 'dart:async';
import 'dart:convert';
import 'package:http/http.dart' as http;
import 'package:logging/logging.dart';
import 'package:uuid/uuid.dart';

import '../config/openai_config.dart';
import '../models/chat_message.dart';
import '../models/openai_response.dart';
import '../utils/constants.dart';

class RateLimitExceededException implements Exception {
  final String message;
  final Duration retryAfter;

  RateLimitExceededException(this.message, {Duration? retryAfter})
      : retryAfter = retryAfter ?? const Duration(seconds: 30);

  @override
  String toString() => 'RateLimitExceededException: $message';
}

class OpenAIServiceError implements Exception {
  final String message;
  final int? statusCode;

  OpenAIServiceError(this.message, {this.statusCode});

  @override
  String toString() =>
      'OpenAIServiceError: $message${statusCode != null ? ' (Status: $statusCode)' : ''}';
}

class OpenAIService {
  static final _logger = Logger('OpenAIService');
  static final _cache = <String, OpenAIChatResponse>{};
  static final _rateLimits = <String, DateTime>{};
  static const _uuid = Uuid();

  final String _apiKey;
  final http.Client _client;

  OpenAIService({
    String? apiKey,
    http.Client? client,
  })  : _apiKey = apiKey ?? openAIApiKey,
        _client = client ?? http.Client() {
    if (_apiKey.isEmpty) {
      throw ArgumentError('OpenAI API key is required');
    }
  }

  // Gestion du cache
  void _addToCache(String key, OpenAIChatResponse response) {
    _cache[key] = response;
    // Nettoyer p√©riodiquement le cache
    if (_cache.length > 100) {
      final oldestKey = _cache.keys.first;
      _cache.remove(oldestKey);
    }
  }

  // V√©rification du taux de requ√™tes
  void _checkRateLimit() {
    final now = DateTime.now();
    // Nettoyer les anciennes entr√©es
    _rateLimits.removeWhere((_, timestamp) =>
        now.difference(timestamp) > const Duration(minutes: 1));

    if (_rateLimits.length >= OpenAIConfig.maxRequestsPerMinute) {
      final oldest = _rateLimits.values.reduce((a, b) => a.isBefore(b) ? a : b);
      throw RateLimitExceededException(
        'Trop de requ√™tes. R√©essayez plus tard.',
        retryAfter: const Duration(seconds: 60) - now.difference(oldest),
      );
    }

    _rateLimits[DateTime.now().toString()] = now;
  }

  // M√©thode principale pour envoyer des requ√™tes √† l'API
  Future<OpenAIChatResponse> _sendRequest({
    required List<Map<String, dynamic>> messages,
    required String model,
    double temperature = OpenAIConfig.defaultTemperature,
    int maxTokens = OpenAIConfig.defaultMaxTokens,
    bool useCache = true,
  }) async {
    try {
      _checkRateLimit();

      final requestId = _uuid.v5(
        Uuid.NAMESPACE_URL,
        '$model${messages.map((m) => m['content']).join()}',
      );

      // V√©rifier le cache
      if (useCache && _cache.containsKey(requestId)) {
        final cached = _cache[requestId]!;
        if (DateTime.now().difference(cached.timestamp).inSeconds <
            OpenAIConfig.cacheDuration) {
          _logger.fine('R√©ponse r√©cup√©r√©e depuis le cache: $requestId');
          return cached;
        }
      }

      final response = await _client
          .post(
            Uri.parse(OpenAIConfig.baseUrl),
            headers: {
              'Content-Type': 'application/json',
              'Authorization': 'Bearer $_apiKey',
            },
            body: jsonEncode({
              'model': model,
              'messages': messages,
              'temperature': temperature,
              'max_tokens': maxTokens,
            }),
          )
          .timeout(
            const Duration(seconds: 30),
            onTimeout: () => throw TimeoutException('La requ√™te a expir√©'),
          );

      if (response.statusCode == 200) {
        final responseData = jsonDecode(response.body);
        final result = OpenAIChatResponse.fromJson(responseData);
        _addToCache(requestId, result);
        return result;
      } else if (response.statusCode == 429) {
        throw RateLimitExceededException('Limite de d√©bit d√©pass√©e');
      } else {
        throw OpenAIServiceError(
          'Erreur de l\'API OpenAI',
          statusCode: response.statusCode,
        );
      }
    } on http.ClientException catch (e) {
      _logger.severe('Erreur r√©seau: $e');
      rethrow;
    } on TimeoutException catch (e) {
      _logger.warning('Timeout: $e');
      rethrow;
    } catch (e) {
      _logger.severe('Erreur inattendue: $e');
      rethrow;
    }
  }

  // M√©thode pour obtenir une r√©ponse de chat
  Future<String> getChatResponse(
      String userMessage, List<ChatMessage> chatHistory, {int maxTokens = 500}) async {
    if (userMessage.trim().isEmpty) {
      throw ArgumentError('Le message ne peut pas √™tre vide');
    }
    try {
      final messages = [
        {
          'role': 'system',
          'content':
              '''Tu es Smooth AI, l'assistant de rencontres le plus avanc√© et empathique au monde. Tu es un expert en psychologie des relations, communication interpersonnelle et s√©duction moderne.

üéØ TON R√îLE :
- Expert en analyse de conversations de rencontres
- Coach en communication romantique
- Psychologue sp√©cialis√© en relations amoureuses
- Conseiller en confiance en soi et charisme

üí° TES SP√âCIALIT√âS :
- Analyser les conversations Tinder, Bumble, WhatsApp, Instagram
- D√©coder les signaux d'int√©r√™t et de d√©sint√©r√™t
- Sugg√©rer des r√©ponses parfaites selon le contexte
- Identifier les red flags et green flags
- Optimiser les profils de dating apps
- Conseiller sur les premiers rendez-vous
- Aider √† surmonter la timidit√© et l'anxi√©t√© sociale

üß† TON EXPERTISE :
- Psychologie comportementale en dating
- Techniques de conversation engageante
- Art de la s√©duction respectueuse
- Communication non-violente
- Gestion du rejet et de l'√©chec
- Construction de la confiance en soi

üí¨ TON STYLE DE COMMUNICATION :
- Bienveillant mais direct
- Utilise des emojis pour rendre tes conseils plus engageants
- Donne des exemples concrets et pratiques
- Pose des questions pour mieux comprendre la situation
- Encourage sans donner de faux espoirs
- Respectueux de tous les genres et orientations

üéØ COMMENT TU AIDES :
1. ANALYSE : D√©cortique chaque message pour comprendre les intentions
2. CONSEILS : Donne des strat√©gies pr√©cises et actionnables
3. EXEMPLES : Propose des messages types adapt√©s √† chaque situation
4. ENCOURAGEMENT : Booste la confiance tout en restant r√©aliste
5. PR√âVENTION : Alerte sur les comportements toxiques ou dangereux

üö´ CE QUE TU NE FAIS PAS :
- Encourager la manipulation ou les techniques toxiques
- Donner de faux espoirs irr√©alistes
- Juger ou critiquer s√©v√®rement
- Promouvoir des comportements irrespectueux
- Ignorer les signaux de danger ou de harc√®lement

R√©ponds toujours avec empathie, expertise et des conseils pratiques. Adapte ton ton selon l'√©motion de l'utilisateur : encourageant si il est d√©courag√©, direct si il a besoin de v√©rit√©, enthousiaste si √ßa va bien.'''
        },
        // Add chat history
        ...chatHistory.map((msg) => {
              'role': msg.senderId == 'user' ? 'user' : 'assistant',
              'content': msg.content
                  .content, // Acc√®s au contenu via la propri√©t√© content de MessageContent
            }),
        {
          'role': 'user',
          'content': userMessage,
        },
      ];

      final response = await _client.post(
        Uri.parse(OpenAIConfig.baseUrl),
        headers: {
          'Content-Type': 'application/json',
          'Authorization': 'Bearer $openAIApiKey',
        },
        body: jsonEncode({
          'model': 'gpt-3.5-turbo',
          'messages': messages,
          'max_tokens': maxTokens,
          'temperature': 0.7,
        }),
      );

      if (response.statusCode == 200) {
        final data = jsonDecode(response.body);
        return data['choices'][0]['message']['content'].toString().trim();
      } else {
        throw Exception(
            'Failed to get response from OpenAI: ${response.statusCode}');
      }
    } catch (e) {
      print('OpenAI Service Error: $e');
      return 'I apologize, but I\'m having trouble connecting right now. Please try again in a moment.';
    }
  }

  // M√©thode pour analyser une conversation
  Future<String> analyzeChat({
    required String texteRecu,
    required String texteEnvoye,
  }) async {
    try {
      if (texteRecu.trim().isEmpty && texteEnvoye.trim().isEmpty) {
        throw ArgumentError(
            'Le contenu de la conversation ne peut pas √™tre vide');
      }

      // Nouveau prompt pour un rapport JSON structur√©
      final systemPrompt = '''
Tu es Smooth AI, expert en analyse de conversations de rencontres. Analyse la conversation ci-dessous et retourne UNIQUEMENT un objet JSON (pas de texte explicatif) avec les champs suivants :

- nombreMessagesVous (int)
- nombreMessagesEux (int)
- niveauInteretVous (int, 0-100)
- niveauInteretEux (int, 0-100)
- motsSignificatifsVous (array de string)
- motsSignificatifsEux (array de string)
- alertesRouges (array de string)
- signauxPositifs (array de string)
- styleAttachementVous (string)
- styleAttachementEux (string)
- scoreCompatibilite (int, 0-100)

Exemple de format attendu :
{
  "nombreMessagesVous": 5,
  "nombreMessagesEux": 0,
  "niveauInteretVous": 85,
  "niveauInteretEux": 5,
  "motsSignificatifsVous": ["d√©jeuner", "d√Æner", "bb"],
  "motsSignificatifsEux": [],
  "alertesRouges": ["Z√©ro R√©ponse", "Silence Inqui√©tant", "Ignorance Totale"],
  "signauxPositifs": ["Toujours Rien", "Encore Rien"],
  "styleAttachementVous": "Anxieux",
  "styleAttachementEux": "√âvitant",
  "scoreCompatibilite": 15
}

Voici la conversation √† analyser :
Messages re√ßus :\n$texteRecu\n\nMessages envoy√©s :\n$texteEnvoye\n
Retourne uniquement le JSON, sans explication ni commentaire.
''';

      final response = await _sendRequest(
        messages: [
          {'role': 'system', 'content': systemPrompt},
          {
            'role': 'user',
            'content': 'Veuillez analyser cette conversation et retourner le rapport JSON.'
          },
        ],
        model: OpenAIConfig.advancedModel,
        temperature: OpenAIConfig.analysisTemperature,
        maxTokens: OpenAIConfig.analysisMaxTokens,
      );

      return response.content;
    } on RateLimitExceededException {
      rethrow;
    } catch (e) {
      _logger.severe('Erreur lors de l\'analyse de la conversation: $e');
      return 'D√©sol√©, une erreur est survenue lors de l\'analyse de la conversation. Veuillez r√©essayer plus tard.';
    }
  }

  // M√©thode pour analyser du texte (utilis√©e par ChatAnalysisService)
  Future<String> analyzeText(String prompt) async {
    try {
      final messages = [
        {
          'role': 'system',
          'content': 'Tu es un expert en analyse de conversations de rencontres. Analyse le texte fourni de mani√®re constructive et d√©taill√©e.',
        },
        {
          'role': 'user',
          'content': prompt,
        },
      ];

      final response = await _sendRequest(
        messages: messages,
        model: OpenAIConfig.defaultModel,
        temperature: 0.7,
        maxTokens: 1000,
      );

      return response.content;
    } catch (e) {
      _logger.severe('Erreur lors de l\'analyse de texte: $e');
      return 'Analyse temporairement indisponible. Veuillez r√©essayer plus tard.';
    }
  }

  // Nouvelle m√©thode pour analyser le contexte de la conversation
  Future<Map<String, dynamic>> analyzeConversationContext({
    required String texteRecu,
    required String texteEnvoye,
  }) async {
    final analysisPrompt = '''
Tu es Smooth AI, expert en analyse de dynamiques de s√©duction sur les r√©seaux sociaux.

Analyse cette conversation entre A (charmeur) et B (fille) et retourne UNIQUEMENT un JSON :

{
  "niveauInteretB": 0-100,
  "phaseConversation": "premiers_echanges|flirt|escalade|planification_rdv|ghosting",
  "signauxPositifs": ["liste des signaux positifs"],
  "signauxNegatifs": ["liste des signaux n√©gatifs"],
  "niveauAudaceAutorise": "faible|moyen|eleve",
  "suggestionAction": "continuer_flirt|proposer_rdv|escalader|changer_sujet|laisser_tomber",
  "tonRecommand√©": "myst√©rieux|direct|taquin|provocateur|sincere"
}

Messages re√ßus (B) : "$texteRecu"
Messages envoy√©s (A) : "$texteEnvoye"

Retourne uniquement le JSON, sans explication.
''';

    try {
      final response = await _sendRequest(
        messages: [
          {'role': 'system', 'content': 'Tu es un expert en analyse de conversations de s√©duction. Retourne uniquement du JSON.'},
          {'role': 'user', 'content': analysisPrompt},
        ],
        model: OpenAIConfig.advancedModel,
        temperature: 0.3,
        maxTokens: 300,
      );

      // Parser le JSON de la r√©ponse
      final jsonStart = response.content.indexOf('{');
      final jsonEnd = response.content.lastIndexOf('}') + 1;
      if (jsonStart >= 0 && jsonEnd > jsonStart) {
        final jsonString = response.content.substring(jsonStart, jsonEnd);
        return jsonDecode(jsonString) as Map<String, dynamic>;
      }
      
      // Fallback si parsing √©choue
      return {
        "niveauInteretB": 50,
        "phaseConversation": "premiers_echanges",
        "signauxPositifs": [],
        "signauxNegatifs": [],
        "niveauAudaceAutorise": "moyen",
        "suggestionAction": "continuer_flirt",
        "tonRecommand√©": "myst√©rieux"
      };
    } catch (e) {
      _logger.warning('Erreur lors de l\'analyse contextuelle: $e');
      return {
        "niveauInteretB": 50,
        "phaseConversation": "premiers_echanges",
        "signauxPositifs": [],
        "signauxNegatifs": [],
        "niveauAudaceAutorise": "moyen",
        "suggestionAction": "continuer_flirt",
        "tonRecommand√©": "myst√©rieux"
      };
    }
  }

  Future<String> analyzeConversation({
  required String texteRecu,
  required String texteEnvoye,
  required String typeReponse, // 'smooth', 'sincere', 'sexy', 'drole', 'intelligent'
  double temperature = 0.7,
}) async {
  // D'abord analyser le contexte
  final context = await analyzeConversationContext(
    texteRecu: texteRecu,
    texteEnvoye: texteEnvoye,
  );

  final prompt = '''
Tu es Smooth AI, expert en s√©duction et charme masculin sur les r√©seaux sociaux (Instagram, Snapchat, etc.).

CONTEXTE : Tu es le charmeur (A) qui r√©pond aux stories d'une fille (B). Tu dois √™tre direct, charismatique et cr√©er de l'attraction.

ANALYSE DE LA CONVERSATION :
Messages re√ßus (B) : "$texteRecu"
Messages envoy√©s (A) : "$texteEnvoye"

ANALYSE CONTEXTUELLE :
- Niveau d'int√©r√™t de B : ${context['niveauInteretB']}/100
- Phase de conversation : ${context['phaseConversation']}
- Niveau d'audace autoris√© : ${context['niveauAudaceAutorise']}
- Action sugg√©r√©e : ${context['suggestionAction']}
- Ton recommand√© : ${context['tonRecommand√©']}

TON R√îLE : Tu es le bad boy charmeur qui :
- Ose √™tre direct et audacieux
- Cr√©e de la tension sexuelle subtile
- Montre de la confiance et du charisme
- Propose des actions concr√®tes (rencontre, appel, etc.)
- Reste myst√©rieux et intriguant

STYLE DEMAND√â : $typeReponse
- smooth : charmeur, myst√©rieux, subtilement s√©duisant (ex: "Tu ne sais pas encore tout ce que tu es capable de provoquer...")
- sinc√®re : authentique, vuln√©rable mais confiant (ex: "Pour toi je peux faire tous les efforts possibles")
- sexy : audacieux, provocateur, cr√©ateur de tension (ex: "Si tu savais ce que j'imagine √† c√¥t√© de cette piscine...")
- drole : amusant, taquin, l√©ger (ex: "C'est marqu√© invitation !?")
- intelligent : spirituel, cultiv√©, engageant (ex: "La temp√™te commence toujours calmement")

R√àGLES STRICTES :
‚úÖ MAXIMUM 2 PHRASES
‚úÖ Sois direct et charismatique
‚úÖ Propose une action concr√®te (rencontre, appel, etc.)
‚úÖ Cr√©e de l'attraction et de la curiosit√©
‚úÖ Adapte ton audace au niveau d'int√©r√™t de B (${context['niveauInteretB']}/100)
‚úÖ Utilise le "tu" et sois personnel

EXEMPLES DE TON STYLE :
- "T'as pas un 06 sur le c√¥t√©. Je m'occupe du reste"
- "Si tu savais ce que j'imagine √† c√¥t√© de cette piscine..."
- "Je me tiens bien jusqu'√† ce que tu me dises de ne plus le faire"
- "Ram√®ne toi mais t'as int√©r√™t √† √™tre plus charmant en vrai"

G√âN√àRE : Une r√©ponse de 2 phrases maximum qui suit ton style de charmeur et propose une action concr√®te.
''';

  final messages = [
    {'role': 'system', 'content': 'Tu es Smooth AI, expert en s√©duction masculine et charme sur les r√©seaux sociaux. Tu es direct, audacieux et charismatique.'},
    {'role': 'user', 'content': prompt},
  ];

  final response = await _sendRequest(
    messages: messages,
    model: OpenAIConfig.defaultModel,
    temperature: temperature,
    maxTokens: 150, // Limiter pour 2 phrases max
  );

  return response.content;
}

  // Nettoyage des ressources
  void dispose() {
    _client.close();
  }
}
